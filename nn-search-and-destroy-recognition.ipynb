{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FEATURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_FEATURES:\n",
    "    from fastai import *\n",
    "    from fastai.vision import *\n",
    "    from fastai.callbacks import *\n",
    "    from arch import RingGeMNet, GeMNet, L2Norm, GeM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./train -> points to index dir, but if you have train_images.csv and feats no need to have images \n",
    "COMP_DATA_DIR = Path('.')\n",
    "\n",
    "ti_fname = 'train_images.gz'\n",
    "try:\n",
    "    df = pd.read_pickle(ti_fname)\n",
    "except:\n",
    "    df = pd.DataFrame({'Image' : sorted(get_image_files(COMP_DATA_DIR / 'train', recurse=True))})\n",
    "    df.to_pickle(ti_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "DO_FULL_SIZE = False \n",
    "\n",
    "if EXTRACT_FEATURES:\n",
    "\n",
    "    NUM_WORKERS=8\n",
    "\n",
    "    class ImageListAbsPath(ImageList):\n",
    "        def open(self, fn:PathOrStr)->Image:\n",
    "            return open_image(fn.replace('./',''))\n",
    "\n",
    "    tfms = (None, None)\n",
    "    if DO_FULL_SIZE:\n",
    "        BS=1\n",
    "        data = (ImageList.from_df(df,path='', cols=['Image'])\n",
    "                .split_none()\n",
    "                .label_const()\n",
    "                .transform(tfms, resize_method=ResizeMethod.NO)\n",
    "                .databunch(bs=BS, num_workers=NUM_WORKERS)\n",
    "                .normalize(imagenet_stats)\n",
    "               ) \n",
    "        data.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.train_ds)\n",
    "        data.train_dl.dl.batch_sampler.drop_last = False\n",
    "    if not DO_FULL_SIZE:\n",
    "        BS=64\n",
    "        data = (ImageList.from_df(df,path='', cols=['Image'])\n",
    "                .split_none()\n",
    "                .label_const()\n",
    "                .transform(tfms, resize_method=ResizeMethod.SQUISH, size=SIZE)\n",
    "                .databunch(bs=BS, num_workers=NUM_WORKERS)\n",
    "                .normalize(imagenet_stats)\n",
    "               ) \n",
    "        data.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.train_ds)\n",
    "        data.train_dl.dl.batch_sampler.drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = models.resnet152 if EXTRACT_FEATURES else None\n",
    "model_fname =  'resnet152_i200_l1000-256'\n",
    "basename_suffix = 'cut-extractor-2scales6patches-gem3'\n",
    "size_fname = 'full' if DO_FULL_SIZE else str(SIZE)\n",
    "\n",
    "basename = f'{model_fname or arch.__name__}_{size_fname}_{basename_suffix}.pth'\n",
    "print(basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_FEATURES:\n",
    "    class Extractor(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.l2norm = L2Norm()\n",
    "            self.pool   = GeM(3.) #nn.AdaptiveMaxPool2d(1)\n",
    "        def forward(self, x):\n",
    "            b,d,ny,nx = x.shape\n",
    "            f0  = self.l2norm(self.pool(x)).view(b,1,d)        \n",
    "            return f0\n",
    "    \n",
    "    learn = cnn_learner(data, arch,pretrained=True, custom_head=Extractor(),\n",
    "                       metrics=[accuracy], cut= -1,\n",
    "                       loss_func=nn.CrossEntropyLoss())\n",
    "\n",
    "    if model_fname:\n",
    "        learn = learn.load(model_fname, strict=False)\n",
    "    else:\n",
    "        model_fname = arch.__name__\n",
    "    learn.summary()\n",
    "    InferenceNet =  learn.model\n",
    "else:\n",
    "    learn, InferenceNet = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS=16\n",
    "\n",
    "qi_fname = 'query_images.gz'\n",
    "try:\n",
    "    qdf = pd.read_pickle(qi_fname)\n",
    "except:    \n",
    "    qdf = pd.DataFrame({'Image' : sorted(get_image_files(COMP_DATA_DIR / 'test', recurse=True))})\n",
    "    qdf.to_pickle(qi_fname)\n",
    "qdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_FEATURES:\n",
    "    BS=1 if DO_FULL_SIZE else 64\n",
    "    qdata = (ImageList.from_df(qdf,path='', cols=['Image'])\n",
    "            .split_none()\n",
    "            .label_const()\n",
    "            .transform(tfms, \n",
    "                       resize_method=ResizeMethod.NO if DO_FULL_SIZE else ResizeMethod.SQUISH, \n",
    "                       size=None if DO_FULL_SIZE else SIZE)\n",
    "            .databunch(bs=BS, num_workers=NUM_WORKERS)\n",
    "            .normalize(imagenet_stats)\n",
    "           ) \n",
    "    qdata.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(qdata.train_ds)\n",
    "    qdata.train_dl.dl.batch_sampler.drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vectors_batched(data,model,flip=False):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    n_flip = 2 if flip else 1\n",
    "    n_img = len(data.train_ds) * n_flip\n",
    "    bs = data.batch_size\n",
    "    vectors = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (img,label) in enumerate(progress_bar(data.train_dl)):\n",
    "            st=idx*bs*n_flip\n",
    "            fin=min((idx+1)*bs*n_flip, n_img)\n",
    "            if flip:\n",
    "                img = torch.cat((img,img.flip([3])))\n",
    "            out = model(img).cpu()\n",
    "            if vectors is None: vectors = torch.zeros(n_img, *out.shape[1:])\n",
    "            if flip:\n",
    "                n = fin - st\n",
    "                vectors[st:fin:2    ,...] = out[:n//2,...]\n",
    "                vectors[st+1:fin+1:2,...] = out[n//2:,...]\n",
    "            else:\n",
    "                vectors[st:fin,...] = out\n",
    "    return vectors\n",
    "\n",
    "def extract_vectors_batched_multi(data,model):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    n_img = len(data.train_ds)\n",
    "    bs = data.batch_size\n",
    "    vectors = None\n",
    "    #hook = hook_outputs([learn.model[8]])#, learn.model[6]))\n",
    "    \n",
    "    #extractor = Extractor().cuda().eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (img,label) in enumerate(progress_bar(data.train_dl)):\n",
    "            st=idx*bs\n",
    "            fin=min((idx+1)*bs, n_img)\n",
    "            layer_output = model(img).cpu()\n",
    "            if vectors is None:\n",
    "#                vectors = [torch.zeros(n_img, layer_output.shape[1]) for layer_output in hook.stored]\n",
    "                vectors = torch.zeros(n_img, *layer_output.shape[1:]) \n",
    "            vectors[st:fin,...] = layer_output\n",
    "\n",
    "            #for i, layer_output in enumerate(hook.stored):\n",
    "            #    vectors[i][st:fin,...] = extractor(layer_output)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = True\n",
    "p_flip = 'flip' if flip else ''\n",
    "try:\n",
    "    print(\"Attempting to load QUERY features from disk...\", end=\"\")\n",
    "    query_features = torch.load( f'query{p_flip}_{basename}')\n",
    "    print(\"OK\")\n",
    "except:\n",
    "    print(\"Failed. Computing features...\")\n",
    "    query_features = extract_vectors_batched(qdata,InferenceNet, flip)\n",
    "    torch.save(query_features, f'query{p_flip}_{basename}')\n",
    "try:\n",
    "    print(\"Attempting to load TRAIN features from disk...\", end=\"\")\n",
    "    index_features = torch.load( f'train{p_flip}_{basename}')\n",
    "    print(\"OK\")\n",
    "except:\n",
    "    print(\"Failed. Computing features...\")\n",
    "    index_features = extract_vectors_batched(data, InferenceNet, flip)\n",
    "    torch.save(index_features, f'train{p_flip}_{basename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features, index_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets do the nearest neighbor search and create the submission\n",
    "import faiss\n",
    "def flatten(list2d): return list(itertools.chain(*list2d))\n",
    "\n",
    "query_fnames = flatten([[x.stem, x.stem] for x in qdf.Image.tolist()])\n",
    "index_fnames = flatten([[x.stem, x.stem] for x in df.Image.tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, InferenceNet, co, res, flat_config, cpu_index, index = None, None, None, None, None, None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_pcawhitenlearn(X):\n",
    "\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # Learning PCA w/o annotations\n",
    "    m = X.mean(dim=0, keepdim=True)\n",
    "    Xc = X - m\n",
    "    Xcov = Xc.t() @ Xc\n",
    "    Xcov = (Xcov + Xcov.t()) / (2*N)\n",
    "    eigval, eigvec = torch.symeig(Xcov,eigenvectors=True)\n",
    "    order = eigval.argsort(descending=True)\n",
    "    eigval = eigval[order]\n",
    "    eigvec = eigvec[:, order]\n",
    "\n",
    "    P = torch.inverse(torch.sqrt(torch.diag(eigval))) @ eigvec.t()\n",
    "    \n",
    "    return m, P\n",
    "\n",
    "def t_whitenapply(X, m, P, dimensions=None):\n",
    "    \n",
    "    if not dimensions: dimensions = P.shape[1]\n",
    "\n",
    "    X = (X-m) @ P[:,:dimensions]\n",
    "    X = X / (torch.norm(X, dim=1, keepdim=True) + 1e-6)\n",
    "    return X\n",
    "\n",
    "def get_idxs_and_dists(_query_features, _index_features, index_type='', BS = 32):\n",
    "    \n",
    "    if False:\n",
    "        index_transforms = []\n",
    "        for index_transform in index_type.split(','):\n",
    "            m = re.match(r'PCAW(\\d+)?', index_transform)\n",
    "            if m is not None:\n",
    "                dimensions = int(m[1]) if m[1] is not None else _index_features.shape[-1]\n",
    "                print(f\"Applying {dimensions} PCA, Whitening and L2Norm...\", end=\"\")\n",
    "                m, P = t_pcawhitenlearn(_index_features)\n",
    "                _index_features = t_whitenapply(_index_features, m, P,dimensions=dimensions).unsqueeze(1)\n",
    "                _query_features = t_whitenapply(_query_features, m, P,dimensions=dimensions).unsqueeze(1)\n",
    "                print(\"done\")\n",
    "\n",
    "            elif index_transform not in ['L2norm']: index_transforms.append(index_transform)\n",
    "\n",
    "        index_type = ','.join(index_transforms)\n",
    "        print(index_type)\n",
    "    else:\n",
    "         _index_features = _index_features.unsqueeze(1)\n",
    "         _query_features = _query_features.unsqueeze(1)\n",
    "        \n",
    "    if isinstance(_query_features, Tensor): query_features = _query_features.numpy()\n",
    "    if isinstance(_index_features, Tensor): index_features = _index_features.numpy()\n",
    "    max_hits = 20\n",
    "    \n",
    "    n_patches = query_features.shape[1]\n",
    "    n_queries = query_features.shape[0]\n",
    "\n",
    "    print(query_features.shape, index_features.shape, n_queries, n_patches)\n",
    "    \n",
    "    flat_config = faiss.GpuIndexFlatConfig()\n",
    "    flat_config.device = 0\n",
    "    res = faiss.StandardGpuResources()\n",
    "    co = faiss.GpuMultipleClonerOptions()\n",
    "    co.shard=True\n",
    "    co.shard_type=1\n",
    "    co.useFloat16=False\n",
    "    _index = faiss.index_factory(index_features.shape[1], index_type)#, faiss.METRIC_INNER_PRODUCT)\n",
    "    try:\n",
    "        index = _index #faiss.index_cpu_to_all_gpus(_index,co=co) #\n",
    "        print(\"Index in GPU\")\n",
    "    except:\n",
    "        index = _index\n",
    "        print(\"Index in CPU\")\n",
    "    print(\"Training index...\", end=\"\")\n",
    "    index.train(index_features)\n",
    "    print(\"done\")\n",
    "    print(\"Adding features to index...\", end=\"\")\n",
    "    index.add(index_features)\n",
    "    print(\"done\")\n",
    "    out_dists = np.zeros((len(query_features), max_hits), dtype=np.float32)\n",
    "    out_idxs  = np.zeros((len(query_features), max_hits), dtype=np.int32)\n",
    "    NUM_QUERY = len (query_features)\n",
    "    for ind in progress_bar(range(0, len(query_features), BS)):\n",
    "        fin = ind+BS\n",
    "        if fin > NUM_QUERY: fin = NUM_QUERY\n",
    "        q_descs = query_features[ind:fin]\n",
    "        D, I = index.search(q_descs, max_hits)\n",
    "        out_dists[ind:fin] = D\n",
    "        out_idxs[ind:fin] = I // n_patches\n",
    "    return out_idxs, out_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.omp_get_max_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faiss.omp_set_num_threads(31)\n",
    "index_type=f\"PCAW{query_features.shape[-1]},L2norm,Flat\"\n",
    "#index_type=\"PCAW512,L2norm,IVF4096,PQ16\"\n",
    "#index_type=\"Flat\"\n",
    "\n",
    "#out_idxs, out_dists = get_idxs_and_dists(\n",
    "#    torch.cat((query_features[0],query_features[1]),dim=-1).squeeze(1), \n",
    "#    torch.cat((index_features[0],index_features[1]),dim=-1).squeeze(1), BS = 32*4, index_type=index_type)\n",
    "\n",
    "out_idxs, out_dists = get_idxs_and_dists(\n",
    "    query_features.squeeze(1), \n",
    "    index_features.squeeze(1), BS = 32*4, index_type=index_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(out_dists.reshape((-1,int(out_idxs.shape[1]*1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'idx_{basename}.npy',  out_idxs)\n",
    "np.save(f'dist_{basename}.npy', out_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_fname = 'test_submission.csv'\n",
    "sample_df = pd.read_csv('test.csv')\n",
    "sample_df['images'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_idxs[0]//2, out_idxs[1]//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "idx = np.concatenate([out_idxs[i], out_idxs[i+1]], axis=0)\n",
    "dst = np.concatenate([out_dists[i],out_dists[i+1]], axis=0) \n",
    "u_idx = np.unique(idx,return_index=True)[1]\n",
    "i_dst = dst[u_idx]\n",
    "o_dst =np.argsort(i_dst)\n",
    "print(idx, o_dst, i_dst)\n",
    "print(idx[u_idx[o_dst]]//2)\n",
    "\n",
    "i = 2\n",
    "idx = np.concatenate([out_idxs[i], out_idxs[i+1]], axis=0)//2\n",
    "dst = np.concatenate([out_dists[i],out_dists[i+1]], axis=0) \n",
    "u_idx = np.unique(idx,return_index=True)[1]\n",
    "i_dst = dst[u_idx]\n",
    "o_dst =np.argsort(i_dst)\n",
    "print(idx, o_dst, i_dst)\n",
    "print(idx[u_idx[o_dst]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = {}\n",
    "for i, query_fname in progress_bar(enumerate(query_fnames), total=len(query_fnames)):\n",
    "    #_out_idxs=out_idxs.reshape(-1,200)[i][np.unique(out_idxs.reshape(-1,200)[i],return_index=True)[1]]\n",
    "    if i % 2: continue\n",
    "    idx = np.concatenate([out_idxs[i], out_idxs[i+1]], axis=0)//2\n",
    "    dst = np.concatenate([out_dists[i],out_dists[i+1]], axis=0) \n",
    "    u_idx = np.unique(idx,return_index=True)[1]\n",
    "    i_dst = dst[u_idx]\n",
    "    o_dst =np.argsort(i_dst)\n",
    "    _out_idxs = idx[u_idx[o_dst]]\n",
    "\n",
    "    #_out_idxs=out_idxs[i][np.unique(out_idxs[i],return_index=True)[1]]\n",
    "    ids = [index_fnames[x*2] for x in _out_idxs[:100]]\n",
    "    sub[query_fname] = ' '.join(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({'id' : list(sub.keys()), 'images':list(sub.values())})\n",
    "sub_df = pd.concat([sub_df, sample_df]).drop_duplicates(subset=['id'])\n",
    "sub_df.to_csv(sub_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.iloc[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_path(p):\n",
    "    fn = str(p.name)\n",
    "    return p.parent / fn[0] / fn[1] / fn[2] / fn\n",
    "def image_results(row, n= 12):\n",
    "    r = [open_image(fix_path(Path('test') / (row.id + '.jpg')))]\n",
    "    r.extend([open_image(fix_path(Path('index') / (id + '.jpg'))) for id in row.images.split(' ')[:n]])\n",
    "    return r\n",
    "show_all(image_results(sub_df.iloc[0]),r=4,figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c landmark-retrieval-2019 -f {sub_fname} -m '{basename} {index_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c landmark-retrieval-2019 -v > submissions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.read_csv('submissions.csv')\n",
    "submissions.iloc[0].publicScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
